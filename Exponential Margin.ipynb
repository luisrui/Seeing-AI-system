{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cb379b-9a8d-444a-99c9-4cf2c9cc9770",
   "metadata": {},
   "source": [
    "# Exponential Margin\n",
    "### Xuying Ning\n",
    "### All right reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31bbef94-a4a8-4b28-bffc-0e89c0839eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from torch import optim\n",
    "from facenet_pytorch import fixed_image_standardization, training\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4748b2b3-9210-43c4-99e2-ee798e53f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'crop-mask-face/confidence'\n",
    "file_list = os.listdir(base_dir)\n",
    "file_list = [item for item in file_list if '.jpg' in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01150106-be27-4e31-98a2-d4e7ee887737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "model= resnet50(pretrained = True, progress = True)\n",
    "from torch import nn\n",
    "\n",
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        self.fc = nn.Linear(2048, 50)\n",
    "        # self.softmax = torch.nn.Softmax(dim = 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "model.fc = net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ef5247-2225-42be-84bb-9684c4697708",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.load_state_dict(torch.load('model_parameter_unES.pth'), strict=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "score_list = []\n",
    "for file in file_list:\n",
    "    src = os.path.join(base_dir,file)\n",
    "    img = cv2.imread(src)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.transpose(2,1,0)\n",
    "    img = torch.from_numpy(img)\n",
    "    # print(img.shape)\n",
    "    img = transforms.Resize((224,224))(img)\n",
    "    # print(img.shape)\n",
    "    img = fixed_image_standardization(img)\n",
    "    img = img.reshape(1, 3, 224, 224).to(device)\n",
    "    # print(img.shape)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "        ps = torch.exp(outputs)\n",
    "        _,prediction = torch.max(ps, 1)\n",
    "        maxexp = np.max(ps.cpu().numpy())\n",
    "        average = np.average(ps.cpu().numpy())\n",
    "        score = maxexp/average\n",
    "        score_list.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6986ba-40e8-4db1-8a46-36275edfa53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_target_mark = np.percentile(score_list,85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e379a5d4-86ee-4880-a11e-b7bbccc037a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=ToTensor()):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dira (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = cv2.imread(img_name)\n",
    "        # image = image.view((224,224,3))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # image = cv2.equalizeHist(image)\n",
    "        image = Image.fromarray(image)\n",
    "        # print(type(image))\n",
    "        # # image = np.transpose(image,(1,2,0)) \n",
    "        label = self.landmarks_frame.iloc[idx, 1]\n",
    "        label = np.array(label)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e97f911d-ff8d-45fb-8ae7-9dbe756958b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :  tensor([3], device='cuda:0') , Score:  50.0\n",
      "Prediction :  tensor([28], device='cuda:0') , Score:  49.996582\n",
      "Prediction :  tensor([1], device='cuda:0') , Score:  49.99156\n",
      "Prediction :  tensor([24], device='cuda:0') , Score:  50.0\n",
      "Prediction :  tensor([34], device='cuda:0') , Score:  23.298098\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import fixed_image_standardization, training\n",
    "preprocessing = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224)),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "\n",
    "testset = CustomImageDataset(csv_file = 'test.csv',\n",
    "                              root_dir='crop-mask-face/test/',\n",
    "                             transform = preprocessing)\n",
    "testloader = DataLoader(testset, batch_size=1,\n",
    "                        shuffle=True, num_workers=0)\n",
    "right_pred_score = []\n",
    "wrong_pred_score = []\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(testloader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        ps = torch.exp(outputs)\n",
    "        _,prediction = torch.max(ps, 1)\n",
    "        maxexp = np.max(ps.cpu().numpy())\n",
    "        # print(maxexp)\n",
    "        average = np.average(ps.cpu().numpy())\n",
    "        score = maxexp/average\n",
    "        if i < 5:\n",
    "            print(\"Prediction : \", prediction, \", Score: \", score)\n",
    "        if prediction == classes:\n",
    "            right_pred_score.append(score)\n",
    "        else:\n",
    "            wrong_pred_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e56ca48-24c7-4fd2-9aaa-9f049cee47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_score = right_pred_score + wrong_pred_score \n",
    "target_mark = np.percentile(target_score,15)\n",
    "margin = target_mark - non_target_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49af6e19-a904-44a8-93cf-5ea1162bc2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4264989852905288"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
